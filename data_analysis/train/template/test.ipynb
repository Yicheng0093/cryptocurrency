{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"enter your code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(\"/kaggle/input/merge-data-1h-and-1d/merged_data_1d.csv\")\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(merged_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout  \n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau  \n",
    "\n",
    "data = merged_data[features]\n",
    "\n",
    "\n",
    "X = data.drop('close_price', axis=1)\n",
    "y = data['close_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def create_dataset(data, time_step):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step):\n",
    "        X.append(data[i:(i + time_step), :])  \n",
    "        y.append(data[i + time_step, 0]) \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "time_step = 7\n",
    "\n",
    "X, y = create_dataset(data_scaled, time_step)\n",
    "\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.3))  \n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001) \n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test), \n",
    "          callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_rescaled = scaler.inverse_transform(np.concatenate((y_pred, np.zeros((y_pred.shape[0], data.shape[1] - 1))), axis=1))[:, 0]\n",
    "y_test_rescaled = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], data.shape[1] - 1))), axis=1))[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "rmse = np.sqrt(mse)  \n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled) \n",
    "r2 = r2_score(y_test_rescaled, y_pred_rescaled)  \n",
    "\n",
    "\n",
    "direction_actual = np.sign(np.diff(y_test_rescaled))  \n",
    "direction_predicted = np.sign(np.diff(y_pred_rescaled))  \n",
    "\n",
    "\n",
    "direction_accuracy = np.mean(direction_actual == direction_predicted)\n",
    "\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'R2 (Coefficient of Determination): {r2:.2f}')\n",
    "print(f'Direction Accuracy: {direction_accuracy:.2f}')\n",
    "\n",
    "\n",
    "evaluation_metrics = {\n",
    "    'Metric': ['MSE', 'RMSE', 'MAE', 'R2', 'Direction Accuracy'],\n",
    "    'Value': [mse, rmse, mae, r2, direction_accuracy]\n",
    "}\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "\n",
    "df_metrics.to_csv('evaluation_metrics.csv', index=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_rescaled, color='blue', label='Actual Price', linewidth=2)\n",
    "plt.plot(y_pred_rescaled, color='red', label='Predicted Price', linewidth=2)\n",
    "plt.title('Actual vs Predicted Close Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dates = merged_data['date'].tail(len(y_test_rescaled)).values  \n",
    "\n",
    "\n",
    "prediction_error = y_test_rescaled - y_pred_rescaled\n",
    "\n",
    "\n",
    "direction_accuracy = np.sign(y_test_rescaled[1:] - y_test_rescaled[:-1]) == np.sign(y_pred_rescaled[1:] - y_pred_rescaled[:-1])\n",
    "direction_accuracy = np.concatenate(([np.nan], direction_accuracy)) \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Actual Price': y_test_rescaled,\n",
    "    'Predicted Price': y_pred_rescaled,\n",
    "    'Prediction Error': prediction_error,\n",
    "    'Direction Accuracy': direction_accuracy\n",
    "})\n",
    "\n",
    "\n",
    "results_df.to_csv('pred.csv', index=False)\n",
    "\n",
    "print(\"Results with additional data have been saved to 'predictions_with_additional_data.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6612373,
     "sourceId": 10930986,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6797017,
     "sourceId": 11145420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
